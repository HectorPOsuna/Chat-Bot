#!/bin/bash
# ============================================
# ENTRYPOINT - Ollama Service
# Inicia Ollama y descarga modelos automÃ¡ticamente
# ============================================

set -e

echo "ğŸš€ Iniciando Ollama Service..."

# Iniciar Ollama en background
ollama serve &
OLLAMA_PID=$!

echo "â³ Esperando a que Ollama estÃ© listo..."

# Esperar a que Ollama estÃ© disponible
max_attempts=30
attempt=0
while [ $attempt -lt $max_attempts ]; do
    if curl -sf http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama estÃ¡ listo!"
        break
    fi
    attempt=$((attempt + 1))
    echo "   Intento $attempt/$max_attempts..."
    sleep 2
done

if [ $attempt -eq $max_attempts ]; then
    echo "âŒ Error: Ollama no respondiÃ³ despuÃ©s de $max_attempts intentos"
    exit 1
fi

# FunciÃ³n para verificar si un modelo estÃ¡ instalado
model_exists() {
    ollama list | grep -q "$1"
}

# Descargar modelos necesarios si no existen
echo "ğŸ“¦ Verificando modelos necesarios..."

if ! model_exists "llama3.2:3b"; then
    echo "â¬‡ï¸  Descargando llama3.2:3b (esto puede tardar varios minutos)..."
    ollama pull llama3.2:3b
    echo "âœ… llama3.2:3b descargado"
else
    echo "âœ… llama3.2:3b ya estÃ¡ instalado"
fi

if ! model_exists "nomic-embed-text"; then
    echo "â¬‡ï¸  Descargando nomic-embed-text..."
    ollama pull nomic-embed-text
    echo "âœ… nomic-embed-text descargado"
else
    echo "âœ… nomic-embed-text ya estÃ¡ instalado"
fi

echo ""
echo "ğŸ‰ Ollama configurado correctamente con todos los modelos"
echo "ğŸ“Š Modelos disponibles:"
ollama list
echo ""
echo "ğŸ”— Ollama API disponible en http://localhost:11434"
echo ""

# Mantener el contenedor corriendo
wait $OLLAMA_PID
