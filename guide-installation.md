# ğŸ“˜ GuÃ­a de InstalaciÃ³n y Uso - AguiAI

**Asistente AcadÃ©mico Inteligente para Consultas Estudiantiles**

Esta guÃ­a proporciona instrucciones completas para instalar, configurar, validar y usar el sistema AguiAI.

---

## ğŸ“‘ Ãndice

1. [Requisitos del Sistema](#-requisitos-del-sistema)
2. [InstalaciÃ³n](#-instalaciÃ³n)
3. [ConfiguraciÃ³n Inicial](#-configuraciÃ³n-inicial)
4. [Sistemas Implementados](#-sistemas-implementados)
5. [ValidaciÃ³n y Pruebas](#-validaciÃ³n-y-pruebas)
6. [Uso del Sistema](#-uso-del-sistema)
7. [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)

---

## ğŸ–¥ï¸ Requisitos del Sistema

### Hardware MÃ­nimo

| Componente | MÃ­nimo | Recomendado |
|------------|--------|-------------|
| **RAM** | 8 GB | 16 GB |
| **CPU** | 4 cores | 8 cores |
| **Disco** | 10 GB libres | 20 GB libres |
| **GPU** | No requerida | Opcional (acelera Ollama) |

### Software Requerido

- âœ… **Node.js** v18 o superior â†’ [Descargar](https://nodejs.org/)
- âœ… **Ollama** â†’ [Descargar](https://ollama.ai/)
- âœ… **Git** â†’ [Descargar](https://git-scm.com/)
- âš ï¸ **Docker** (Opcional) â†’ [Descargar](https://www.docker.com/)

### Verificar Instalaciones

```bash
# Verificar Node.js
node --version
# Salida esperada: v18.x.x o superior

# Verificar npm
npm --version

# Verificar Ollama
ollama --version

# Verificar Git
git --version
```

---

## ğŸ“¦ InstalaciÃ³n

Elige el mÃ©todo de instalaciÃ³n que prefieras:

<details>
<summary><b>OpciÃ³n A: InstalaciÃ³n Local (Recomendado)</b></summary>

### Paso 1: Instalar y Configurar Ollama

```bash
# Windows/Mac/Linux: Descargar desde https://ollama.ai/
# DespuÃ©s de instalar, descargar modelos:

ollama pull llama3.2:3b
ollama pull nomic-embed-text
```

**Verificar modelos instalados:**
```bash
ollama list
```

### Paso 2: Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/chat-bot.git
cd chat-bot
```

### Paso 3: Instalar Dependencias del Backend

```bash
cd server
npm install
```

**Dependencias instaladas:**
- `express` - Framework web
- `cors` - Manejo de CORS
- `pdf-parse` - Procesamiento de PDFs
- `multer` - Subida de archivos
- `natural` - Procesamiento de lenguaje natural

### Paso 4: Instalar Dependencias del Frontend

```bash
cd ../chat-frontend
npm install
```

**Dependencias instaladas:**
- `react` - Biblioteca UI
- `vite` - Build tool
- `axios` - Cliente HTTP
- `react-markdown` - Renderizado Markdown

### Paso 5: Iniciar el Sistema

**Terminal 1 - Backend:**
```bash
cd server
node index.js
```

**Terminal 2 - Frontend:**
```bash
cd chat-frontend
npm run dev
```

### Paso 6: Acceder al Sistema

- ğŸŒ **Frontend**: http://localhost:5173
- ğŸ”Œ **Backend API**: http://localhost:3000
- ğŸ¤– **Ollama**: http://localhost:11434

</details>

<details>
<summary><b>OpciÃ³n B: InstalaciÃ³n con Docker</b></summary>

> **Nota**: Docker es una alternativa a la instalaciÃ³n local de Ollama.

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/chat-bot.git
cd chat-bot
```

### Paso 2: Iniciar Servicios con Docker Compose

```bash
docker compose up -d --build
```

**Servicios iniciados:**
- `ollama` - Motor de IA
- `api` - Backend Node.js
- `frontend` - AplicaciÃ³n React (opcional)

### Paso 3: Descargar Modelos en Contenedor

```bash
docker exec -it chat-bot-ollama-1 ollama pull llama3.2:3b
docker exec -it chat-bot-ollama-1 ollama pull nomic-embed-text
```

### Paso 4: Verificar Estado

```bash
docker ps
```

### Paso 5: Acceder al Sistema

- ğŸŒ **Frontend**: http://localhost:5173
- ğŸ”Œ **Backend API**: http://localhost:3000
- ğŸ¤– **Ollama**: http://localhost:11434

</details>

---

## âš™ï¸ ConfiguraciÃ³n Inicial

### Variables de Entorno (Opcional)

Crea un archivo `.env` en la carpeta `server/`:

```env
# URL de Ollama
OLLAMA_URL=http://localhost:11434

# Puerto del servidor
PORT=3000
```

### Estructura de Carpetas

El sistema crearÃ¡ automÃ¡ticamente estas carpetas al iniciar:

```
server/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/                    # PDFs originales subidos
â”‚   â”œâ”€â”€ processed/               # Documentos procesados (JSON)
â”‚   â”œâ”€â”€ embeddings/              # Vectores de embeddings
â”‚   â””â”€â”€ training-prompts.json    # Prompts de entrenamiento
```

### Verificar InstalaciÃ³n

```bash
curl http://localhost:3000/health
```

**Respuesta esperada:**
```json
{
  "status": "success",
  "data": {
    "server": "running",
    "ollama": "http://localhost:11434",
    "rag": {
      "totalDocuments": 0,
      "totalChunks": 0
    },
    "training": {
      "totalPrompts": 5,
      "enabledPrompts": 5,
      "categories": 3
    }
  }
}
```

---

## ğŸ¯ Sistemas Implementados

AguiAI incluye dos sistemas complementarios de entrenamiento:

### 1ï¸âƒ£ Training Prompts (Respuestas Predefinidas)

**Â¿QuÃ© es?**
Sistema de pares pregunta-respuesta con matching inteligente por similitud.

**CaracterÃ­sticas:**
- âš¡ Respuestas instantÃ¡neas (<0.5s)
- ğŸ¯ Matching por similitud de embeddings (â‰¥85%)
- ğŸ“ Soporte para variaciones de preguntas
- ğŸ·ï¸ CategorizaciÃ³n de prompts
- âœï¸ CRUD completo mediante API

**Ejemplo de Prompt:**
```json
{
  "question": "Â¿A quÃ© universidad perteneces?",
  "variations": [
    "Â¿De quÃ© universidad eres?",
    "Â¿CuÃ¡l es tu instituciÃ³n?"
  ],
  "answer": "Soy parte de la Universidad AutÃ³noma de Sinaloa...",
  "category": "instituciÃ³n"
}
```

**Endpoints Disponibles:**
- `GET /training` - Listar prompts
- `POST /training` - Crear prompt
- `PUT /training/:id` - Actualizar prompt
- `DELETE /training/:id` - Eliminar prompt
- `GET /training/stats` - EstadÃ­sticas

---

### 2ï¸âƒ£ Sistema RAG (Documentos PDF)

**Â¿QuÃ© es?**
Retrieval-Augmented Generation: entrena la IA con documentos institucionales.

**Pipeline de Procesamiento:**
```
PDF â†’ ExtracciÃ³n â†’ Limpieza â†’ Chunking â†’ Embeddings â†’ Vector Store â†’ BÃºsqueda
```

**CaracterÃ­sticas:**
- ğŸ“„ Procesamiento automÃ¡tico de PDFs
- ğŸ” BÃºsqueda semÃ¡ntica por similitud
- ğŸ“Š Chunks de ~1000 caracteres con overlap
- ğŸ’¾ Almacenamiento en JSON
- ğŸ¯ Top-K resultados mÃ¡s relevantes

**Endpoints Disponibles:**
- `POST /documents/upload` - Subir PDF
- `GET /documents` - Listar documentos
- `DELETE /documents/:id` - Eliminar documento
- `POST /documents/search` - Buscar contexto

---

### ğŸ”„ Prioridad de Respuestas

El sistema sigue este orden automÃ¡ticamente:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Training Prompts                â”‚
â”‚     â”œâ”€ Match â‰¥85%? â†’ Respuesta      â”‚
â”‚     â””â”€ No match â†“                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. Sistema RAG                     â”‚
â”‚     â”œâ”€ Documentos? â†’ Contexto       â”‚
â”‚     â””â”€ Sin docs â†“                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. Ollama BÃ¡sico                   â”‚
â”‚     â””â”€ Conocimiento general         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… ValidaciÃ³n y Pruebas

### Reporte 1: Training Prompts

**Objetivo:** Verificar matching inteligente

**Prueba:**
```bash
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿A quÃ© universidad perteneces?", "useTraining": true}'
```

**Resultado Esperado:**
```json
{
  "status": "success",
  "data": {
    "reply": "Soy parte de la Universidad AutÃ³noma de Sinaloa...",
    "source": "training",
    "similarity": "100%",
    "time": "0.12"
  }
}
```

**Tabla de ValidaciÃ³n:**

| Pregunta | Match | Similitud | Estado |
|----------|-------|-----------|--------|
| "Â¿A quÃ© universidad perteneces?" | prompt_001 | 100% | âœ… |
| "Â¿De quÃ© escuela eres?" | prompt_001 | 92% | âœ… |
| "Â¿CuÃ¡l es tu instituciÃ³n?" | prompt_001 | 95% | âœ… |
| "Â¿Horario de atenciÃ³n?" | prompt_002 | 88% | âœ… |

---

### Reporte 2: Sistema RAG

**Objetivo:** Verificar procesamiento de PDFs

**Prueba 1 - Subir PDF:**
```bash
curl -X POST http://localhost:3000/documents/upload \
  -F "pdf=@manual_uas.pdf"
```

**Resultado:**
```json
{
  "status": "success",
  "data": {
    "id": "doc_1733445600000_manual",
    "filename": "manual_uas.pdf",
    "numPages": 45,
    "totalChunks": 89,
    "textLength": 125000
  }
}
```

**Prueba 2 - BÃºsqueda SemÃ¡ntica:**
```bash
curl -X POST http://localhost:3000/documents/search \
  -H "Content-Type: application/json" \
  -d '{"query": "requisitos de admisiÃ³n", "topK": 3}'
```

**Resultados:**

| Chunk | Similitud | Preview |
|-------|-----------|---------|
| chunk_12 | 87.5% | "Los requisitos de admisiÃ³n incluyen..." |
| chunk_34 | 82.3% | "Para ingresar a la facultad..." |
| chunk_56 | 79.1% | "DocumentaciÃ³n necesaria..." |

---

### Reporte 3: Prioridades del Sistema

**Escenario 1:** Pregunta con match en Training
```bash
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿A quÃ© universidad perteneces?", "useTraining": true, "useRAG": true}'
```
âœ… **Resultado:** `source: "training"` (prioridad alta)

**Escenario 2:** Sin match, con RAG
```bash
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿Requisitos de admisiÃ³n?", "useTraining": true, "useRAG": true}'
```
âœ… **Resultado:** `source: "rag"` (prioridad media)

**Escenario 3:** Sin match ni RAG
```bash
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿QuÃ© es la IA?", "useTraining": true, "useRAG": true}'
```
âœ… **Resultado:** `source: "basic"` (prioridad baja)

---

### Reporte 4: Rendimiento

| Tipo de Respuesta | Tiempo Promedio | Observaciones |
|-------------------|-----------------|---------------|
| Training Prompt | **0.15s** | InstantÃ¡neo, sin Ollama |
| RAG (3 chunks) | **2.45s** | BÃºsqueda + generaciÃ³n |
| Ollama BÃ¡sico | **1.80s** | Solo generaciÃ³n |
| Procesamiento PDF | **15-30s** | Depende del tamaÃ±o |

---

### Reporte 5: CRUD de Training Prompts

| OperaciÃ³n | Endpoint | MÃ©todo | Estado |
|-----------|----------|--------|--------|
| Listar | `/training` | GET | âœ… |
| Crear | `/training` | POST | âœ… |
| Actualizar | `/training/:id` | PUT | âœ… |
| Eliminar | `/training/:id` | DELETE | âœ… |
| EstadÃ­sticas | `/training/stats` | GET | âœ… |

---

### Reporte 6: IntegraciÃ³n Frontend-Backend

**Funcionalidades Validadas:**

- âœ… EnvÃ­o de mensajes desde UI
- âœ… RecepciÃ³n de respuestas con Markdown
- âœ… VisualizaciÃ³n de fuentes (RAG)
- âœ… Toggle Training/RAG funcional
- âœ… Subida de PDFs desde interfaz
- âœ… Manejo de errores y loading states

---

## ğŸš€ Uso del Sistema

### Para Estudiantes

#### Hacer una Consulta

1. Abrir navegador en http://localhost:5173
2. Escribir pregunta en el chat
3. Presionar Enter o clic en "Enviar"
4. Recibir respuesta instantÃ¡nea

**Ejemplo:**
```
Usuario: Â¿CuÃ¡l es el horario de atenciÃ³n?
AguiAI: El horario de atenciÃ³n de la Facultad de InformÃ¡tica 
        MazatlÃ¡n es de lunes a viernes de 8:00 AM a 8:00 PM.
        
        Fuente: Training Prompt (100% similitud)
```

---

### Para Administradores

#### 1. Agregar Nuevo Prompt de Training

```bash
curl -X POST http://localhost:3000/training \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Â¿Tienen biblioteca?",
    "variations": [
      "Â¿Hay biblioteca?",
      "Â¿DÃ³nde estÃ¡ la biblioteca?",
      "Â¿Cuentan con biblioteca?"
    ],
    "answer": "SÃ­, contamos con biblioteca en el edificio principal, abierta de lunes a viernes de 7:00 AM a 9:00 PM.",
    "category": "instalaciones"
  }'
```

#### 2. Subir Documento Institucional

```bash
curl -X POST http://localhost:3000/documents/upload \
  -F "pdf=@reglamento_2024.pdf"
```

#### 3. Actualizar Prompt Existente

```bash
curl -X PUT http://localhost:3000/training/prompt_002 \
  -H "Content-Type: application/json" \
  -d '{
    "answer": "Nuevo horario: Lunes a viernes de 7:00 AM a 9:00 PM"
  }'
```

#### 4. Eliminar Prompt

```bash
curl -X DELETE http://localhost:3000/training/prompt_005
```

#### 5. Ver EstadÃ­sticas

```bash
curl http://localhost:3000/training/stats
```

**Respuesta:**
```json
{
  "total": 5,
  "enabled": 5,
  "disabled": 0,
  "categories": 3,
  "categoryBreakdown": [
    {"category": "instituciÃ³n", "count": 1},
    {"category": "horarios", "count": 1},
    {"category": "instalaciones", "count": 1}
  ]
}
```

#### 6. Monitorear Sistema

```bash
curl http://localhost:3000/health
```

---

## ğŸ”§ SoluciÃ³n de Problemas

### Problema 1: "Cannot find module 'express'"

**Causa:** Dependencias no instaladas

**SoluciÃ³n:**
```bash
cd server
npm install
```

---

### Problema 2: "Model not found: nomic-embed-text"

**Causa:** Modelo de embeddings no descargado

**SoluciÃ³n:**
```bash
ollama pull nomic-embed-text
ollama list  # Verificar
```

---

### Problema 3: "No hay documentos en el vector store"

**Causa:** No se han subido PDFs

**SoluciÃ³n:**
```bash
curl -X POST http://localhost:3000/documents/upload \
  -F "pdf=@tu_documento.pdf"
```

---

### Problema 4: El servidor no inicia

**Posibles causas:**

1. **Puerto 3000 ocupado**
```bash
# Windows
netstat -ano | findstr :3000

# Linux/Mac
lsof -i :3000
```

2. **Ollama no estÃ¡ corriendo**
```bash
ollama list
# Si falla, reiniciar Ollama
```

3. **Node.js versiÃ³n incorrecta**
```bash
node --version
# Debe ser v18 o superior
```

---

### Problema 5: Respuestas muy lentas

**Optimizaciones:**

1. **Reducir chunks recuperados**
   - Editar `rag-engine.js` lÃ­nea 65
   - Cambiar `topK: 3` a `topK: 2`

2. **Reducir tamaÃ±o de chunks**
   - Editar `chunker.js`
   - Cambiar `chunkSize: 1000` a `chunkSize: 500`

3. **Verificar hardware**
   - MÃ­nimo 8GB RAM
   - CPU con 4+ cores

---

### Problema 6: Error al subir PDF grande

**Causa:** LÃ­mite de tamaÃ±o (10MB por defecto)

**SoluciÃ³n:**
Editar `server/routes/documents.js`:

```javascript
limits: {
  fileSize: 20 * 1024 * 1024  // Cambiar a 20MB
}
```

---

### Problema 7: Training Prompts no funcionan

**Verificar:**

1. **Embeddings generados**
```bash
# Revisar logs del servidor al iniciar
# Debe mostrar: "âœ… Prompt Matcher inicializado"
```

2. **Archivo de prompts existe**
```bash
ls server/data/training-prompts.json
```

3. **Umbral de similitud**
   - Editar `prompt-matcher.js` lÃ­nea 15
   - Ajustar `similarityThreshold: 0.85`

---

## ğŸ“ Soporte

Si encuentras problemas no listados aquÃ­:

1. Revisa los logs del servidor
2. Verifica que Ollama estÃ© corriendo
3. Consulta la documentaciÃ³n de Ollama: https://ollama.ai/
4. Revisa el README.md del proyecto

---

## ğŸ“ Recursos Adicionales

- ğŸ“– [README Principal](./README.md) - DocumentaciÃ³n acadÃ©mica completa
- ğŸ”— [Ollama Documentation](https://ollama.ai/)
- ğŸ”— [React Documentation](https://react.dev/)
- ğŸ”— [Node.js Documentation](https://nodejs.org/)

---

<div align="center">

**AguiAI - Asistente AcadÃ©mico Inteligente**

*Facultad de InformÃ¡tica MazatlÃ¡n*  
*Universidad AutÃ³noma de Sinaloa*

ğŸ‰ **Â¡Sistema listo para usar!** ğŸ‰

</div>
