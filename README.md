# ğŸ¤– Chatbot IA con Node.js + Ollama (Dockerizado)

Este proyecto implementa un **chatbot de Inteligencia Artificial** utilizando:

- **Ollama** â†’ para ejecutar modelos LLM localmente (phi3, llama3, mistral, etc.)
- **Node.js + Express** â†’ como API REST del chatbot
- **Docker + Docker Compose** â†’ para que cualquier persona pueda ejecutarlo sin instalar Ollama ni Node.js localmente

El entorno completo corre en contenedores, lo que permite facilidad de uso, portabilidad y despliegue sencillo.

---

# ğŸš€ CaracterÃ­sticas

- Chatbot IA completamente funcional
- Backend en Node.js consumiendo Ollama por medio de HTTP
- Docker Compose para levantar ambos servicios simultÃ¡neamente
- Ollama con modelo `phi3` incluido
- API REST lista para consumir desde Postman, frontend o mÃ³vil
- Compatible con Windows / Linux / Mac (solo usa Docker)
- Totalmente local y gratuito

---

# ğŸ— Arquitectura del Proyecto

chatbot/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ index.js
â”‚ â”œâ”€â”€ package.json
â”‚ â””â”€â”€ package-lock.json
â”œâ”€â”€ ollama/
â”‚ â””â”€â”€ Dockerfile


### Servicios

| Servicio | Puerto | DescripciÃ³n |
|---------|--------|-------------|
| **Ollama** | 11434 | Ejecuta el modelo LLM dentro de Docker |
| **Backend Node.js** | 3000 | API REST que recibe mensajes y responde con la IA |

---

# ğŸ§© Requisitos previos

Antes de iniciar, necesitas:

- **Docker**: https://www.docker.com/get-started  
- **Docker Compose** (ya viene incluido en Docker Desktop)

No necesitas instalar:

âŒ Node.js  
âŒ Ollama  
âŒ NPM  
âŒ Modelos adicionales  

Todo estÃ¡ dentro de Docker.

---

# âš™ InstalaciÃ³n y uso

#!/bin/bash

echo "=== ğŸ“¦ 1) Clonando repositorio ==="
git clone https://github.com/HectorPOsuna/Chat-Bot && cd Chat-Bot

echo "=== ğŸ‹ 2) Iniciando solo el contenedor de Ollama ==="
docker compose up -d ollama

echo "=== â³ 3) Esperando a que el servidor Ollama estÃ© listo ==="
until docker exec ollama curl -s http://localhost:11434/api/tags > /dev/null 2>&1; do
  echo "   â†’ Ollama aÃºn no responde, reintentando..."
  sleep 3
done

echo "=== ğŸ§  4) Precargando modelo llama3.2:3b ==="
docker exec -it ollama ollama pull llama3.2:3b

echo "=== ğŸ” 5) Verificando modelos instalados ==="
docker exec -it ollama ollama list

echo "=== ğŸš€ 6) Construyendo e iniciando todos los servicios ==="
docker compose up -d --build

echo "=== ğŸ“¡ 7) Verificando estado de contenedores ==="
docker ps

echo "=== ğŸ§ª 8) Probando conexiÃ³n al API del chatbot ==="
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt":"Hola, Â¿estÃ¡s funcionando?"}'

echo "=== âœ” InstalaciÃ³n finalizada ==="

