# Asistente AcadÃ©mico Inteligente "AguiAI" para Consultas Estudiantiles

<div align="center">

![AguiAI](https://img.shields.io/badge/AguiAI-Asistente%20Acad%C3%A9mico-blue)
![Node.js](https://img.shields.io/badge/Node.js-v18+-green)
![React](https://img.shields.io/badge/React-v19-blue)
![Ollama](https://img.shields.io/badge/Ollama-llama3.2-orange)
![Docker](https://img.shields.io/badge/Docker-Opcional-blue)

**Sistema de asistencia acadÃ©mica inteligente con capacidades de RAG y entrenamiento por prompts**

</div>

---

## ğŸ“‹ Tabla de Contenidos

1. [DefiniciÃ³n del Modelo](#definiciÃ³n-del-modelo)
   - [Antecedentes](#antecedentes)
   - [MetodologÃ­a Previa](#metodologÃ­a-previa)
2. [TecnologÃ­as Utilizadas](#tecnologÃ­as-utilizadas)
3. [Funcionamiento del Sistema](#funcionamiento-del-sistema)
4. [Arquitectura e IntegraciÃ³n](#arquitectura-e-integraciÃ³n)
5. [InstalaciÃ³n](#instalaciÃ³n)
6. [ValidaciÃ³n de Funcionalidades](#validaciÃ³n-de-funcionalidades)
7. [Uso del Sistema](#uso-del-sistema)

---

## ğŸ“ DefiniciÃ³n del Modelo

### Antecedentes

#### Semblanza

**AguiAI** (Asistente de GuÃ­a Inteligente con IA) es un sistema de asistencia acadÃ©mica desarrollado para la **Facultad de InformÃ¡tica MazatlÃ¡n** de la **Universidad AutÃ³noma de Sinaloa**. El proyecto surge como respuesta a la necesidad de proporcionar informaciÃ³n institucional precisa, consistente y accesible las 24 horas del dÃ­a a estudiantes, aspirantes y visitantes.

El sistema integra tecnologÃ­as de inteligencia artificial de Ãºltima generaciÃ³n, especÃ­ficamente modelos de lenguaje grandes (LLMs) ejecutados localmente mediante Ollama, combinados con tÃ©cnicas avanzadas de recuperaciÃ³n de informaciÃ³n (RAG - Retrieval-Augmented Generation) y entrenamiento por prompts predefinidos.

#### MotivaciÃ³n

La motivaciÃ³n principal para el desarrollo de AguiAI incluye:

1. **Accesibilidad de InformaciÃ³n**: Proporcionar acceso inmediato a informaciÃ³n institucional sin depender de horarios de atenciÃ³n administrativa.

2. **Consistencia en Respuestas**: Garantizar que las preguntas frecuentes reciban respuestas uniformes y precisas mediante el sistema de training prompts.

3. **Escalabilidad**: Capacidad de manejar mÃºltiples consultas simultÃ¡neas sin degradaciÃ³n del servicio.

4. **ActualizaciÃ³n DinÃ¡mica**: Facilitar la actualizaciÃ³n de informaciÃ³n mediante la carga de documentos PDF (manuales, reglamentos) y la gestiÃ³n de prompts de entrenamiento.

5. **Privacidad y SoberanÃ­a de Datos**: Ejecutar el modelo de IA localmente sin depender de servicios externos, garantizando la privacidad de las consultas estudiantiles.

6. **ReducciÃ³n de Carga Administrativa**: Automatizar respuestas a consultas repetitivas, permitiendo al personal administrativo enfocarse en tareas mÃ¡s complejas.

### MetodologÃ­a Previa

El desarrollo de AguiAI se fundamenta en una arquitectura de tres capas que integra mÃºltiples tecnologÃ­as modernas:

#### TecnologÃ­as Utilizadas

##### Frontend
- **React 19**: Biblioteca de JavaScript para construir interfaces de usuario interactivas
- **Vite**: Herramienta de construcciÃ³n rÃ¡pida para desarrollo frontend
- **Axios**: Cliente HTTP para comunicaciÃ³n con el backend
- **React-Markdown**: Renderizado de respuestas formateadas en Markdown

##### Backend
- **Node.js 18+**: Entorno de ejecuciÃ³n de JavaScript del lado del servidor
- **Express**: Framework web minimalista para Node.js
- **Multer**: Middleware para manejo de archivos multipart/form-data
- **PDF-Parse**: ExtracciÃ³n de texto de documentos PDF
- **Natural**: Procesamiento de lenguaje natural para tokenizaciÃ³n

##### Inteligencia Artificial
- **Ollama**: Plataforma para ejecutar modelos de lenguaje grandes localmente
  - **llama3.2:3b**: Modelo principal para generaciÃ³n de respuestas
  - **nomic-embed-text**: Modelo para generaciÃ³n de embeddings vectoriales

##### Infraestructura (Opcional)
- **Docker**: ContainerizaciÃ³n de servicios
  - **Nota Importante**: La implementaciÃ³n en Docker es una **alternativa** a hospedar Ollama localmente. El sistema puede ejecutarse completamente en la mÃ¡quina local sin Docker, simplemente instalando Ollama directamente en el sistema operativo.

##### Almacenamiento
- **Sistema de Archivos**: Almacenamiento de documentos procesados y embeddings en formato JSON
- **Estructura de Datos**: OrganizaciÃ³n jerÃ¡rquica de PDFs, documentos procesados y vectores de embeddings

---

## ğŸ”§ TecnologÃ­as Utilizadas

### 1. React (Frontend)

**FunciÃ³n**: Interfaz de usuario interactiva para el chatbot.

**CaracterÃ­sticas Implementadas**:
- Componentes funcionales con Hooks (useState, useEffect, useRef)
- GestiÃ³n de estado para mensajes, historial conversacional y configuraciÃ³n
- Renderizado condicional de respuestas en Markdown
- Auto-scroll a nuevos mensajes
- Toggle para activar/desactivar RAG y Training

**IntegraciÃ³n**: Se comunica con el backend mediante peticiones HTTP (Axios) al endpoint `/chat`.

### 2. Vite (Build Tool)

**FunciÃ³n**: Herramienta de construcciÃ³n y desarrollo para el frontend.

**Ventajas**:
- Hot Module Replacement (HMR) instantÃ¡neo
- Build optimizado para producciÃ³n
- ConfiguraciÃ³n mÃ­nima
- Soporte nativo para ES modules

**Uso**: `npm run dev` para desarrollo, `npm run build` para producciÃ³n.

### 3. Node.js + Express (Backend)

**FunciÃ³n**: Servidor API que coordina todas las operaciones del sistema.

**Responsabilidades**:
- GestiÃ³n de endpoints REST
- Procesamiento de PDFs
- CoordinaciÃ³n entre Training Prompts, RAG y Ollama
- Manejo de archivos y almacenamiento
- GestiÃ³n de CORS para comunicaciÃ³n con frontend

**Arquitectura**:
```
index.js (Servidor principal)
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ documents.js (GestiÃ³n de PDFs)
â”‚   â””â”€â”€ training.js (GestiÃ³n de prompts)
â””â”€â”€ rag/
    â”œâ”€â”€ pdf-processor.js
    â”œâ”€â”€ chunker.js
    â”œâ”€â”€ embeddings.js
    â”œâ”€â”€ vector-store.js
    â”œâ”€â”€ rag-engine.js
    â”œâ”€â”€ prompt-matcher.js
    â””â”€â”€ training-manager.js
```

### 4. Ollama (Motor de IA)

**FunciÃ³n**: Ejecuta modelos de lenguaje grandes localmente sin requerir conexiÃ³n a internet.

**Modelos Utilizados**:

#### llama3.2:3b
- **PropÃ³sito**: GeneraciÃ³n de respuestas conversacionales
- **ParÃ¡metros**: 3 mil millones
- **Uso**: Respuestas a preguntas generales y contextualizadas

#### nomic-embed-text
- **PropÃ³sito**: GeneraciÃ³n de embeddings vectoriales (768 dimensiones)
- **Uso**: 
  - Matching de similitud para Training Prompts
  - BÃºsqueda semÃ¡ntica en documentos RAG

**Ventajas**:
- EjecuciÃ³n local (privacidad garantizada)
- Sin costos por uso
- Sin lÃ­mites de rate
- Respuestas rÃ¡pidas (optimizado para hardware local)

**Nota sobre Docker**: Ollama puede ejecutarse de dos formas:
1. **InstalaciÃ³n Local** (Recomendado para desarrollo): Instalar Ollama directamente en Windows/Linux/macOS
2. **Docker Container** (Alternativa): Ejecutar Ollama en un contenedor Docker para aislamiento

### 5. Docker (Opcional)

**FunciÃ³n**: ContainerizaciÃ³n de servicios para despliegue consistente.

**Servicios Containerizados**:
- `ollama`: Servicio de IA
- `api`: Backend Node.js
- `frontend`: AplicaciÃ³n React (opcional)

**Ventajas**:
- Entorno reproducible
- FÃ¡cil despliegue en diferentes sistemas
- Aislamiento de dependencias

**Importante**: Docker es **opcional**. El sistema funciona perfectamente sin Docker instalando Ollama y Node.js directamente en el sistema operativo.

### 6. Sistema RAG (Retrieval-Augmented Generation)

**FunciÃ³n**: Permite entrenar la IA con documentos PDF institucionales.

**Pipeline de Procesamiento**:
```
PDF â†’ ExtracciÃ³n de Texto â†’ Limpieza â†’ Chunking â†’ Embeddings â†’ Vector Store
```

**Componentes**:
1. **PDF Processor**: Extrae texto de PDFs usando pdf-parse
2. **Chunker**: Divide texto en fragmentos de ~1000 caracteres con overlap
3. **Embeddings Generator**: Genera vectores usando nomic-embed-text
4. **Vector Store**: Almacena y busca por similitud coseno
5. **RAG Engine**: Coordina bÃºsqueda y generaciÃ³n de respuestas

### 7. Training Prompts

**FunciÃ³n**: Sistema de respuestas predefinidas con matching inteligente.

**CaracterÃ­sticas**:
- Matching por similitud de embeddings (umbral 85%)
- Soporte para variaciones de preguntas
- CategorizaciÃ³n de prompts
- CRUD completo mediante API REST
- Prioridad sobre RAG y Ollama

**Almacenamiento**: JSON en `server/data/training-prompts.json`

---

## âš™ï¸ Funcionamiento del Sistema

### Flujo de Procesamiento de Consultas

```
Usuario â†’ Frontend (React) â†’ Backend (Express) â†’ Procesamiento Inteligente â†’ Respuesta
                                                          â†“
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                                           â”‚
                            1. Training Prompts                          2. RAG System
                            (Prioridad Alta)                         (Prioridad Media)
                                    â”‚                                           â”‚
                            Matching â‰¥85%?                              Documentos?
                                    â”‚                                           â”‚
                                   SÃ­                                          SÃ­
                                    â”‚                                           â”‚
                            Respuesta InstantÃ¡nea                    BÃºsqueda SemÃ¡ntica
                                    â”‚                                           â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                    3. Ollama BÃ¡sico
                                                   (Prioridad Baja)
                                                          â”‚
                                                  Conocimiento General
```

### 1. Training Prompts (Primera Prioridad)

**Proceso**:
1. Usuario envÃ­a pregunta
2. Sistema genera embedding de la pregunta
3. Compara con embeddings de prompts almacenados
4. Si similitud â‰¥ 85%, retorna respuesta predefinida
5. Tiempo de respuesta: <0.5 segundos

**Ventajas**:
- Respuestas instantÃ¡neas
- Consistencia garantizada
- No consume recursos de Ollama

### 2. Sistema RAG (Segunda Prioridad)

**Proceso**:
1. Si no hay match en Training Prompts
2. Genera embedding de la pregunta
3. Busca top-3 chunks mÃ¡s similares en documentos
4. Construye prompt con contexto recuperado
5. EnvÃ­a a Ollama con contexto
6. Retorna respuesta contextualizada

**Ventajas**:
- Respuestas basadas en documentos oficiales
- Actualizable mediante carga de PDFs
- Cita fuentes de informaciÃ³n

### 3. Ollama BÃ¡sico (Tercera Prioridad)

**Proceso**:
1. Si no hay match en Training ni contexto en RAG
2. EnvÃ­a pregunta con prompt bÃ¡sico institucional
3. Ollama genera respuesta con conocimiento general
4. Retorna respuesta

**Uso**: Preguntas generales no cubiertas por Training o RAG.

---

## ğŸ—ï¸ Arquitectura e IntegraciÃ³n

### Diagrama de Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND (React)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Chat UI    â”‚  â”‚ PDF Uploader â”‚  â”‚   Settings   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                  â”‚                  â”‚                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                            â”‚ HTTP (Axios)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (Node.js + Express)                    â”‚
â”‚                            â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚              API Routes (Express)                  â”‚           â”‚
â”‚  â”‚  /chat  /training  /documents  /health            â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜           â”‚
â”‚                        â”‚                           â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Training Matcher         â”‚    â”‚    RAG Engine          â”‚    â”‚
â”‚  â”‚  - prompt-matcher.js       â”‚    â”‚  - pdf-processor.js    â”‚    â”‚
â”‚  â”‚  - training-manager.js     â”‚    â”‚  - chunker.js          â”‚    â”‚
â”‚  â”‚  - Similarity Search       â”‚    â”‚  - embeddings.js       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - vector-store.js     â”‚    â”‚
â”‚               â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚                                â”‚                   â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ HTTP API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OLLAMA (Motor IA)                          â”‚
â”‚                                â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                    API Endpoints                        â”‚       â”‚
â”‚  â”‚  /api/chat  /api/generate  /api/embeddings            â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜       â”‚
â”‚                            â”‚                            â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚      llama3.2:3b               â”‚    â”‚  nomic-embed-text      â”‚ â”‚
â”‚  â”‚  (GeneraciÃ³n de Respuestas)    â”‚    â”‚  (Embeddings 768D)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                    â”‚
â”‚  EjecutÃ¡ndose: Local o Docker Container                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### IntegraciÃ³n entre TecnologÃ­as

#### Frontend â†” Backend
- **Protocolo**: HTTP/REST
- **Formato**: JSON
- **Cliente**: Axios
- **Endpoints**: `/chat`, `/training`, `/documents`

#### Backend â†” Ollama
- **Protocolo**: HTTP
- **Endpoints Ollama**:
  - `/api/chat`: Conversaciones con contexto
  - `/api/generate`: GeneraciÃ³n simple
  - `/api/embeddings`: GeneraciÃ³n de vectores
- **Formato**: JSON con streaming opcional

#### Flujo de Datos RAG
```
PDF File â†’ pdf-parse â†’ Text â†’ Natural (Tokenizer) â†’ Chunks
                                                       â†“
                                              Ollama (embeddings)
                                                       â†“
                                              Vector Store (JSON)
                                                       â†“
                                              Similarity Search
                                                       â†“
                                              Context â†’ Ollama (chat)
```

#### Flujo de Training Prompts
```
User Question â†’ Ollama (embedding) â†’ Similarity Comparison
                                            â†“
                                    Training Prompts (JSON)
                                            â†“
                                    Match â‰¥85%? â†’ Predefined Answer
```

---

## ï¿½ DocumentaciÃ³n Adicional

Para informaciÃ³n detallada sobre instalaciÃ³n, validaciÃ³n de funcionalidades y uso del sistema, consulta:

ğŸ“– **[GuÃ­a de InstalaciÃ³n y Uso Completa](./guide-installation.md)**

Esta guÃ­a incluye:
- InstalaciÃ³n paso a paso (local y con Docker)
- ConfiguraciÃ³n del sistema
- Pruebas completas de Training Prompts y RAG
- ValidaciÃ³n de funcionalidades
- Ejemplos de uso con Postman y cURL
- IntegraciÃ³n con Frontend
- SoluciÃ³n de problemas

---

## ğŸ“Š Conclusiones

**AguiAI** representa una soluciÃ³n integral para asistencia acadÃ©mica que:

âœ… **Garantiza privacidad** mediante ejecuciÃ³n local de IA  
âœ… **Proporciona respuestas consistentes** con Training Prompts  
âœ… **Se actualiza fÃ¡cilmente** mediante carga de PDFs  
âœ… **Escala eficientemente** con arquitectura modular  
âœ… **Funciona 24/7** sin intervenciÃ³n humana  
âœ… **Reduce carga administrativa** automatizando consultas frecuentes  

El sistema ha sido validado exitosamente en todas sus funcionalidades y estÃ¡ listo para despliegue en producciÃ³n.

---

## ğŸ“š Referencias

- [Ollama Documentation](https://ollama.ai/)
- [React Documentation](https://react.dev/)
- [Node.js Documentation](https://nodejs.org/)
- [RAG Paper](https://arxiv.org/abs/2005.11401)
- [Llama 3.2 Model Card](https://ollama.ai/library/llama3.2)

---

## ğŸ‘¥ Autores

**Facultad de InformÃ¡tica MazatlÃ¡n**  
Universidad AutÃ³noma de Sinaloa

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia ISC.
